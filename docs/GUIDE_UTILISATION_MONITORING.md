# ğŸ“Š Guide d'Utilisation - Prometheus & Grafana pour MedFlow

## ğŸ¯ Vue d'ensemble

Ce guide vous explique comment utiliser Prometheus et Grafana pour monitorer votre application MedFlow dÃ©ployÃ©e sur Kubernetes.

---

## ğŸ” Partie 1 : Utiliser Prometheus

### AccÃ¨s
- **URL** : http://prometheus.medflow.local
- **Interface** : Query, Alerts, Status

### RequÃªtes PromQL Essentielles pour MedFlow

#### 1. VÃ©rifier que Prometheus collecte les mÃ©triques

```promql
up{job="medflow-backend"}
```

**RÃ©sultat attendu** : `1` (si le backend est accessible)

#### 2. CPU des Pods Backend

```promql
rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m])
```

**Explication** : Taux d'utilisation CPU des pods backend sur 5 minutes

#### 3. MÃ©moire des Pods Backend

```promql
container_memory_working_set_bytes{namespace="medflow", pod=~"backend.*"}
```

**Explication** : MÃ©moire utilisÃ©e par chaque pod backend en bytes

#### 4. Nombre de Pods Backend Actifs

```promql
count(kube_pod_info{namespace="medflow", pod=~"backend.*"})
```

**Explication** : Nombre total de pods backend

#### 5. CPU Moyenne de Tous les Pods Backend

```promql
avg(rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m]))
```

**Explication** : CPU moyenne de tous les pods backend

#### 6. MÃ©moire Moyenne de Tous les Pods Backend

```promql
avg(container_memory_working_set_bytes{namespace="medflow", pod=~"backend.*"})
```

**Explication** : MÃ©moire moyenne de tous les pods backend

#### 7. MÃ©triques du Backend (via endpoint /api/v1/metrics)

```promql
medflow_uptime_seconds{job="medflow-backend"}
```

**Explication** : Temps de fonctionnement du backend en secondes

#### 8. Ã‰tat des Pods MedFlow

```promql
kube_pod_status_phase{namespace="medflow"}
```

**Explication** : Ã‰tat de tous les pods (Running, Pending, Failed, etc.)

#### 9. RequÃªtes HTTP (si implÃ©mentÃ©)

```promql
rate(medflow_http_requests_total[5m])
```

**Explication** : Taux de requÃªtes HTTP par seconde

#### 10. CPU et MÃ©moire des Pods Frontend

```promql
# CPU Frontend
rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"frontend.*"}[5m])

# MÃ©moire Frontend
container_memory_working_set_bytes{namespace="medflow", pod=~"frontend.*"}
```

### Comment Utiliser Prometheus

1. **Ouvrir Prometheus** : http://prometheus.medflow.local
2. **Aller dans l'onglet "Query"**
3. **Taper une requÃªte PromQL** dans le champ de recherche
4. **Cliquer sur "Execute"**
5. **Voir les rÃ©sultats** :
   - **Table** : Valeurs numÃ©riques
   - **Graph** : Graphique temporel

### Exemple Pratique : Monitorer le CPU Backend

1. Tapez : `rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m])`
2. Cliquez sur "Graph"
3. Vous verrez l'Ã©volution du CPU dans le temps

---

## ğŸ“ˆ Partie 2 : Utiliser Grafana

### AccÃ¨s
- **URL** : http://grafana.medflow.local
- **Identifiants** : `admin` / `admin123`

### PremiÃ¨re Connexion

1. Connectez-vous avec `admin` / `admin123`
2. **Changez le mot de passe** (recommandÃ©)
3. Prometheus est dÃ©jÃ  configurÃ© comme source de donnÃ©es

### CrÃ©er un Dashboard pour MedFlow

#### Dashboard 1 : Vue d'Ensemble Backend

1. **CrÃ©er un nouveau dashboard** :
   - Cliquez sur **+** (en haut Ã  droite)
   - SÃ©lectionnez **Create Dashboard**
   - Cliquez sur **Add visualization**

2. **Panel 1 : CPU Backend (Graphique)**

   - **Titre** : "CPU Usage - Backend Pods"
   - **RequÃªte PromQL** :
     ```promql
     rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m]) * 100
     ```
   - **UnitÃ©** : Percent (0-100)
   - **LÃ©gende** : `{{pod}}`

3. **Panel 2 : MÃ©moire Backend (Graphique)**

   - **Titre** : "Memory Usage - Backend Pods"
   - **RequÃªte PromQL** :
     ```promql
     container_memory_working_set_bytes{namespace="medflow", pod=~"backend.*"} / 1024 / 1024
     ```
   - **UnitÃ©** : MB
   - **LÃ©gende** : `{{pod}}`

4. **Panel 3 : Nombre de Pods Backend (Stat)**

   - **Titre** : "Backend Pods Count"
   - **RequÃªte PromQL** :
     ```promql
     count(kube_pod_info{namespace="medflow", pod=~"backend.*"})
     ```
   - **Type** : Stat
   - **UnitÃ©** : short

5. **Panel 4 : Uptime Backend (Stat)**

   - **Titre** : "Backend Uptime"
   - **RequÃªte PromQL** :
     ```promql
     medflow_uptime_seconds{job="medflow-backend"}
     ```
   - **Type** : Stat
   - **UnitÃ©** : seconds

6. **Sauvegarder le dashboard** :
   - Cliquez sur **Save dashboard** (en haut)
   - Nom : "MedFlow - Backend Overview"
   - Dossier : "MedFlow"

#### Dashboard 2 : Vue d'Ensemble Frontend

CrÃ©ez un dashboard similaire pour le frontend :

1. **Panel 1 : CPU Frontend**
   ```promql
   rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"frontend.*"}[5m]) * 100
   ```

2. **Panel 2 : MÃ©moire Frontend**
   ```promql
   container_memory_working_set_bytes{namespace="medflow", pod=~"frontend.*"} / 1024 / 1024
   ```

3. **Panel 3 : Nombre de Pods Frontend**
   ```promql
   count(kube_pod_info{namespace="medflow", pod=~"frontend.*"})
   ```

#### Dashboard 3 : HPA (Auto-scaling)

1. **Panel 1 : Nombre de Pods Backend (HPA)**
   ```promql
   count(kube_pod_info{namespace="medflow", pod=~"backend.*"})
   ```
   - **Type** : Graphique avec lignes de rÃ©fÃ©rence
   - **Ligne min** : 2 (minReplicas)
   - **Ligne max** : 10 (maxReplicas)

2. **Panel 2 : CPU Moyenne (pour HPA)**
   ```promql
   avg(rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m])) * 100
   ```
   - **Ligne de rÃ©fÃ©rence** : 70% (seuil HPA)

3. **Panel 3 : MÃ©moire Moyenne (pour HPA)**
   ```promql
   avg(container_memory_working_set_bytes{namespace="medflow", pod=~"backend.*"}) / 1024 / 1024
   ```
   - **Ligne de rÃ©fÃ©rence** : 80% du limit

#### Dashboard 4 : Ã‰tat des Pods

1. **Panel 1 : Ã‰tat des Pods (Table)**
   ```promql
   kube_pod_status_phase{namespace="medflow"}
   ```
   - **Type** : Table
   - **Colonnes** : pod, phase

2. **Panel 2 : Pods par Ã‰tat (Pie Chart)**
   ```promql
   count by (phase) (kube_pod_status_phase{namespace="medflow"})
   ```
   - **Type** : Pie chart

### Importer un Dashboard Existant

Grafana propose des dashboards prÃªts Ã  l'emploi :

1. **Allez dans Dashboards** > **Import**
2. **Entrez un ID de dashboard** :
   - **315** : Kubernetes Cluster Monitoring
   - **8588** : Kubernetes / Compute Resources / Cluster
   - **6417** : Kubernetes Deployment Statefulset Daemonset metrics
3. **SÃ©lectionnez Prometheus** comme source de donnÃ©es
4. **Cliquez sur Import**

### CrÃ©er une Alerte

#### Exemple : Alerte CPU Ã‰levÃ©

1. **CrÃ©ez un dashboard** avec un graphique CPU
2. **Cliquez sur le graphique** > **Edit**
3. **Onglet Alert** :
   - **Condition** : `WHEN avg() OF query(A, 5m, now) IS ABOVE 0.7`
   - **Evaluation** : Every 5m for 5m
   - **Notifications** : (configurez un contact point)
4. **Sauvegardez**

---

## ğŸ¯ ScÃ©narios d'Utilisation pour MedFlow

### ScÃ©nario 1 : VÃ©rifier la SantÃ© de l'Application

1. **Prometheus** :
   ```promql
   up{namespace="medflow"}
   ```
   - Tous les services doivent retourner `1`

2. **Grafana** :
   - CrÃ©ez un panel avec cette requÃªte
   - Si une valeur est `0`, le service est down

### ScÃ©nario 2 : Monitorer l'Auto-scaling

1. **Grafana Dashboard HPA** :
   - Observez le nombre de pods backend
   - Si CPU > 70%, le HPA devrait crÃ©er plus de pods
   - Si CPU < 70%, le HPA devrait rÃ©duire les pods

2. **VÃ©rifier dans Kubernetes** :
   ```bash
   kubectl get hpa -n medflow -w
   ```

### ScÃ©nario 3 : DÃ©tecter une Surcharge

1. **Prometheus** :
   ```promql
   avg(rate(container_cpu_usage_seconds_total{namespace="medflow", pod=~"backend.*"}[5m])) > 0.7
   ```
   - Si `true`, le backend est surchargÃ©

2. **Grafana** :
   - CrÃ©ez une alerte sur cette mÃ©trique
   - Configurez une notification (email, Slack, etc.)

### ScÃ©nario 4 : Analyser les Performances

1. **Grafana Dashboard** :
   - CPU par pod : Identifiez les pods les plus chargÃ©s
   - MÃ©moire par pod : DÃ©tectez les fuites mÃ©moire
   - Uptime : VÃ©rifiez la stabilitÃ©

---

## ğŸ”§ Commandes Utiles

### VÃ©rifier que Prometheus collecte les mÃ©triques

```bash
# Dans Prometheus, exÃ©cutez :
up{job="medflow-backend"}
```

### VÃ©rifier les mÃ©triques du backend

```bash
# Tester l'endpoint de mÃ©triques
curl http://api.medflow.local/api/v1/metrics
```

### Voir les targets Prometheus

Dans Prometheus :
1. Allez dans **Status** > **Targets**
2. VÃ©rifiez que tous les targets sont "UP"

---

## ğŸ“ Checklist d'Utilisation

### Prometheus
- [ ] AccÃ¨s Ã  http://prometheus.medflow.local
- [ ] Test d'une requÃªte PromQL simple
- [ ] VÃ©rification des targets (Status > Targets)
- [ ] CrÃ©ation d'une requÃªte pour CPU backend
- [ ] CrÃ©ation d'une requÃªte pour mÃ©moire backend

### Grafana
- [ ] Connexion avec admin/admin123
- [ ] VÃ©rification de la source de donnÃ©es Prometheus
- [ ] CrÃ©ation d'un dashboard Backend
- [ ] CrÃ©ation d'un dashboard Frontend
- [ ] Import d'un dashboard Kubernetes (optionnel)
- [ ] CrÃ©ation d'une alerte (optionnel)

---

## ğŸ“ Ressources

- **PromQL** : https://prometheus.io/docs/prometheus/latest/querying/basics/
- **Grafana Dashboards** : https://grafana.com/grafana/dashboards/
- **Documentation Prometheus** : https://prometheus.io/docs/

---

## ğŸ’¡ Astuces

1. **Utilisez des variables** dans Grafana pour rendre les dashboards dynamiques
2. **CrÃ©ez des annotations** pour marquer les dÃ©ploiements
3. **Exportez vos dashboards** pour les partager
4. **Configurez des alertes** pour Ãªtre notifiÃ© des problÃ¨mes

---

**Note** : Les mÃ©triques sont collectÃ©es toutes les 15 secondes. Les graphiques montrent l'Ã©volution dans le temps.

